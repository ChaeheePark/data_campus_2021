{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정수인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text=sent_tokenize(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "vocab=Counter()\n",
    "\n",
    "sentence=[]\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "for i in text:\n",
    "    sentence=word_tokenize(i)\n",
    "    result=[]\n",
    "    \n",
    "    for word in sentence:\n",
    "        word=word.lower()\n",
    "        if word not in stop_words:\n",
    "            if len(word)>2:\n",
    "                result.append(word)\n",
    "                vocab[word]=vocab[word]+1\n",
    "    sentences.append(result)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
     ]
    }
   ],
   "source": [
    "vocab_sorted=sorted(vocab.items(),key=lambda x:x[1],reverse=True)\n",
    "print(vocab_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={}\n",
    "i=0\n",
    "for (word,frequency) in vocab_sorted:\n",
    "    if frequency>1:\n",
    "        i=i+1\n",
    "        word_to_index[word]=i\n",
    "        \n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"이 여름 다시 한번 설레고 싶다 그때 그 여름을 틀어줘 그 여름을 들려줘 이 여름도 언젠가는 그해 여름 오늘이 가장 젊은 내 여름\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이', '여름', '다시', '한번', '설레고', '싶다', '그때', '그', '여름', '을', '틀어줘', '그', '여름', '을', '들려줘', '이', '여름', '도', '언젠가', '는', '그해', '여름', '오늘이', '가장', '젊은', '내', '여름']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt=Okt()\n",
    "\n",
    "token=okt.morphs(example)\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'이': 0, '여름': 1, '다시': 2, '한번': 3, '설레고': 4, '싶다': 5, '그때': 6, '그': 7, '을': 8, '틀어줘': 9, '들려줘': 10, '도': 11, '언젠가': 12, '는': 13, '그해': 14, '오늘이': 15, '가장': 16, '젊은': 17, '내': 18}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={}\n",
    "i=0\n",
    "for voca in token:\n",
    "    if voca not in word_to_index.keys():\n",
    "        word_to_index[voca]=len(word_to_index)\n",
    "        \n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word,word_to_index):\n",
    "    one_hot_vector=[0]*(len(word_to_index))\n",
    "    index=word_to_index[word]\n",
    "    one_hot_vector[index]=1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"여름\",word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"가장\",word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < 과제 >\n",
    "- 1글자 단어 제외하고 one hot 벡터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['여름', '다시', '한번', '설레고', '싶다', '그때', '여름', '틀어줘', '여름', '들려줘', '여름', '언젠가', '그해', '여름', '오늘이', '가장', '젊은', '여름']\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "for i in range(len(token)):\n",
    "    if len(token[i])>1:\n",
    "        words.append(token[i])\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'여름': 0, '다시': 1, '한번': 2, '설레고': 3, '싶다': 4, '그때': 5, '틀어줘': 6, '들려줘': 7, '언젠가': 8, '그해': 9, '오늘이': 10, '가장': 11, '젊은': 12}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={}\n",
    "i=0\n",
    "for voca in words:\n",
    "    if voca not in word_to_index.keys():\n",
    "        word_to_index[voca]=len(word_to_index)\n",
    "        \n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"여름\",word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"이 여름 다시 한번 설레고 싶다. 그때 그 여름을 틀어줘. 그 여름을 들려줘. 이 여름도 언젠가는 그해 여름. 오늘이 가장 젊은 내 여름.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 여름 다시 한번 설레고 싶다 그때 그 여름을 틀어줘 그 여름을 들려줘 이 여름도 언젠가는 그해 여름 오늘이 가장 젊은 내 여름\n",
      "['이', '여름', '다시', '한번', '설레고', '싶다', '그때', '그', '여름', '을', '틀어줘', '그', '여름', '을', '들려줘', '이', '여름', '도', '언젠가', '는', '그해', '여름', '오늘이', '가장', '젊은', '내', '여름']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "okt=Okt()\n",
    "\n",
    "token=re.sub(\"(\\.)\",\"\",text)\n",
    "\n",
    "print(token)\n",
    "\n",
    "token=okt.morphs(token)\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'이': 0, '여름': 1, '다시': 2, '한번': 3, '설레고': 4, '싶다': 5, '그때': 6, '그': 7, '을': 8, '틀어줘': 9, '들려줘': 10, '도': 11, '언젠가': 12, '는': 13, '그해': 14, '오늘이': 15, '가장': 16, '젊은': 17, '내': 18}\n"
     ]
    }
   ],
   "source": [
    "word2index={}\n",
    "bow=[]\n",
    "\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[voca]=len(word2index)\n",
    "        bow.insert(len(word2index)-1,1)\n",
    "    \n",
    "    else:\n",
    "        index=word2index.get(voca)\n",
    "        bow[index]=bow[index]+1\n",
    "        \n",
    "print(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1 2 1]]\n",
      "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus=['you know I want your love, because I love you']\n",
    "vector=CountVectorizer()\n",
    "\n",
    "print(vector.fit_transform(corpus).toarray())\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 2)\t2\n",
      "  (0, 5)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 4)\t2\n"
     ]
    }
   ],
   "source": [
    "print(vector.fit_transform(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1]]\n",
      "{'know': 1, 'want': 3, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text=['you know I want your love, because I love you']\n",
    "vect=CountVectorizer(stop_words=[\"you\",\"your\"])\n",
    "\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1]]\n",
      "{'know': 0, 'want': 2, 'love': 1}\n"
     ]
    }
   ],
   "source": [
    "sw=stopwords.words(\"english\")\n",
    "\n",
    "text=['you know I want your love, because I love you']\n",
    "vect=CountVectorizer(stop_words=sw)\n",
    "\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
